{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ff113f",
   "metadata": {},
   "source": [
    "### importing some important library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58e60bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array , load_img\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce511b",
   "metadata": {},
   "source": [
    "# install the librery\n",
    "\n",
    "because we want to split our data to test and train set we should impliment a new librery\n",
    "split folders do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f01800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b17c29aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: split-folders[full] in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from split-folders[full]) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm->split-folders[full]) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install split-folders[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ccdae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300dec19",
   "metadata": {},
   "source": [
    "# split data\n",
    "\n",
    "split all the images in DataSet folder and then save's them to NewDataset folder\n",
    "80% is train nad 20% is test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68cf8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 624 files [00:03, 170.87 files/s]\n"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio(\"DataSet\", output=\"NewDataset\",\n",
    "    seed=1337, ratio=(.8, 0,.2), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9dff0",
   "metadata": {},
   "source": [
    "# setting the File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff84b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"NewDataset/test/\"\n",
    "train_path = \"NewDataset/train/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c67e94",
   "metadata": {},
   "source": [
    "# Load a train image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ce237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = image.load_img(train_path + \"Glasses/an2i_left_sad_sunglasses_4.pgm\")\n",
    "plt.imshow(img) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d76fcb",
   "metadata": {},
   "source": [
    "# Train set loading\n",
    "\n",
    "because of the data set images format we couldn't load data set with tensorflow and ... so i load it with pour python code with glob function and then i set the y train set of x with 1 = has sunglasses , 0 = hasn't sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4af21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Glass_train = glob.glob(\"NewDataset/train/Glasses/*\")\n",
    "NoGlass_train = glob.glob(\"NewDataset/train/NoGlasses/*\")\n",
    "train_x_path = Glass_train + NoGlass_train\n",
    "train_x = []\n",
    "train_y = np.empty(499)\n",
    "j = 0\n",
    "for i in train_x_path:\n",
    "    if j < 248:\n",
    "        train_y[j] = 1\n",
    "    else :\n",
    "        train_y[j] = 0\n",
    "    img = mpimg.imread(i)\n",
    "    train_x.append(img)\n",
    "    j+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079a22a",
   "metadata": {},
   "source": [
    "# Test set loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a272e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Glass_test = glob.glob(\"NewDataset/test/Glasses/*\")\n",
    "NoGlass_test = glob.glob(\"NewDataset/test/NoGlasses/*\")\n",
    "test_x_path = Glass_test + NoGlass_test\n",
    "test_x = []\n",
    "test_y = np.empty(125)\n",
    "j = 0\n",
    "for i in test_x_path:\n",
    "    if j < 62:\n",
    "        test_y[j] = 1\n",
    "    else :\n",
    "        test_y[j] = 0\n",
    "    img = mpimg.imread(i)\n",
    "    test_x.append(img)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b0ee1",
   "metadata": {},
   "source": [
    "# convert \n",
    "So after loading the data we know it shape is 30 * 32 and we have 499 images in train set and 125 images in test set\n",
    "All of them have list format so we convert it to array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca1fd43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 30, 32)\n",
      "(499,)\n",
      "(125, 30, 32)\n",
      "(125,)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.asarray(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3674b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Glasses',\"non-Glasses\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57899898",
   "metadata": {},
   "source": [
    "# Reshapeing \n",
    "\n",
    "we have 3D array and its really hard for us because mlp can't work with 3D or higher dimentional array so we reshape it to 2D array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4568b8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (499, 960)\n",
      "train_set_y shape: (499,)\n",
      "test_set_x_flatten shape: (125, 960)\n",
      "test_set_y shape: (125,)\n"
     ]
    }
   ],
   "source": [
    "train_x_flatten = train_x.reshape(499,30*32)\n",
    "test_x_flatten = test_x.reshape(test_x.shape[0],test_x.shape[1]*test_x.shape[2])\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd976b",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Now we can model our data with SKLearn librery \n",
    "+ hidden_layer_size :The ith element represents the number of neurons in the ith hidden layer. for example (10,10,10) it means we have 3 hidden layer and in each layer we have 10 nodes\n",
    "+ Max-iter :Maximum number of iterations.\n",
    "+ activation : {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’\n",
    "+ Learning_rate : alpha\n",
    "....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "febf43ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), learning_rate='adaptive',\n",
       "              max_iter=500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (256,128,64,32,),max_iter=500, activation='relu',learning_rate=\"adaptive\",solver=\"adam\")\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5606a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), learning_rate='adaptive',\n",
       "              max_iter=500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(train_x_flatten,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df923ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = mlp.predict(test_x_flatten)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4283fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a8bec9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59  4]\n",
      " [ 4 58]]\n",
      "0.936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_y,pred))\n",
    "print(accuracy_score(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "901bc295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        63\n",
      "         1.0       0.94      0.94      0.94        62\n",
      "\n",
      "    accuracy                           0.94       125\n",
      "   macro avg       0.94      0.94      0.94       125\n",
      "weighted avg       0.94      0.94      0.94       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0299a5dc",
   "metadata": {},
   "source": [
    "Now we check it for 2, 4, 10, 50 node in hidden layer so we can see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e9f791d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 2 element in hidden layer accuracy_score is :  0.496\n",
      "with 4 element in hidden layer accuracy_score is :  0.496\n",
      "with 10 element in hidden layer accuracy_score is :  0.8\n",
      "with 50 element in hidden layer accuracy_score is :  0.84\n"
     ]
    }
   ],
   "source": [
    "element_num = [2,4,10,50]\n",
    "for i in element_num:\n",
    "    testmlp = MLPClassifier(hidden_layer_sizes = (i,),max_iter=500, activation='relu',learning_rate=\"adaptive\",solver=\"adam\")\n",
    "    testmlp.fit(train_x_flatten,train_y)\n",
    "    pred_test = testmlp.predict(test_x_flatten)\n",
    "    print(\"with \" + str(i) +\" element in hidden layer accuracy_score is : \",accuracy_score(test_y, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c882a",
   "metadata": {},
   "source": [
    "# 3 Layer (2 hidden ,1 output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e39887df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912\n"
     ]
    }
   ],
   "source": [
    "Newmlp = MLPClassifier(hidden_layer_sizes = (100,100,),max_iter=500, activation='relu',learning_rate=\"adaptive\",solver=\"adam\")\n",
    "Newmlp.fit(train_x_flatten,train_y)\n",
    "Newpred = Newmlp.predict(test_x_flatten)\n",
    "print(accuracy_score(test_y, Newpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72db3d20",
   "metadata": {},
   "source": [
    "# 4 Layer (3 hidden ,1 output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5479e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n"
     ]
    }
   ],
   "source": [
    "Newmlp = MLPClassifier(hidden_layer_sizes = (128,64,32,),max_iter=500, activation='relu',learning_rate=\"adaptive\",solver=\"adam\")\n",
    "Newmlp.fit(train_x_flatten,train_y)\n",
    "Newpred = Newmlp.predict(test_x_flatten)\n",
    "print(accuracy_score(test_y, Newpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d6509",
   "metadata": {},
   "source": [
    "# 5 Layer (4 hidden ,1 output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e07e6812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952\n"
     ]
    }
   ],
   "source": [
    "Newmlp = MLPClassifier(hidden_layer_sizes = (256,128,64,32,),max_iter=500, activation='relu',learning_rate=\"adaptive\",solver=\"adam\")\n",
    "Newmlp.fit(train_x_flatten,train_y)\n",
    "Newpred = Newmlp.predict(test_x_flatten)\n",
    "print(accuracy_score(test_y, Newpred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
